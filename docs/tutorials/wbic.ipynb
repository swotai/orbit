{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBIC/BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives a tutorial on how to use Watanabe-Bayesian information criterion (WBIC) and Bayesian information criterion (BIC) for feature selection (Watanabe[2010], McElreath[2015], and Vehtari[2016]). The WBIC or BIC is an information criterion. Similar to other criteria (AIC, DIC), the WBIC/BIC endeavors to find the most parsimonious model, i.e., the model that balances fit with complexity. In other words a model (or set of features) that optimizes WBIC/BIC should neither over nor under fit the available data. \n",
    "\n",
    "In this tutorial a data set is simulated using the damped linear trend (DLT) model. This data set is then used to fit DLT models with varying number of features as well as a global local trend model (GLT), and a Error-Trend-Seasonal (ETS) model. The WBIC/BIC criteria is then show to find the true model. \n",
    "\n",
    "Note that we recommend the use of WBIC for full Bayesian and SVI estimators and BIC for MAP estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T21:49:16.127581Z",
     "start_time": "2022-04-28T21:49:13.501781Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import orbit\n",
    "from orbit.models import DLT,ETS, KTRLite, LGT\n",
    "from orbit.utils.simulation import make_trend, make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T21:49:16.132504Z",
     "start_time": "2022-04-28T21:49:16.129880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.4.3\n"
     ]
    }
   ],
   "source": [
    "print(orbit.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code creates random data set (365 observations with 10 features) assuming a DLT model. Of the 10 features 5 are effective regressors; i.e., they are used in the true model to create the data.\n",
    "\n",
    "As an exercise left to the user once you have run the code once try changing the `NUM_OF_EFFECTIVE_REGRESSORS` (line 2), the `SERIES_LEN` (line 3), and the `SEED` (line 4) to see how it effects the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:01:15.716689Z",
     "start_time": "2022-03-25T01:01:15.701163Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_OF_REGRESSORS = 10\n",
    "NUM_OF_EFFECTIVE_REGRESSORS = 4\n",
    "SERIES_LEN = 365\n",
    "SEED = 1\n",
    "# sample some coefficients\n",
    "COEFS = np.random.default_rng(SEED).uniform(-1, 1, NUM_OF_EFFECTIVE_REGRESSORS)\n",
    "trend = make_trend(SERIES_LEN, rw_loc=0.01, rw_scale=0.1)\n",
    "x, regression, coefs = make_regression(series_len=SERIES_LEN, coefs=COEFS)\n",
    "\n",
    "# combine trend and the regression\n",
    "y = trend + regression\n",
    "y = y - y.min()\n",
    "\n",
    "\n",
    "x_extra = np.random.normal(0, 1, (SERIES_LEN, NUM_OF_REGRESSORS - NUM_OF_EFFECTIVE_REGRESSORS))\n",
    "x = np.concatenate([x, x_extra], axis=-1)\n",
    "\n",
    "x_cols = [f\"x{x}\" for x in range(1, NUM_OF_REGRESSORS + 1)]\n",
    "response_col = \"y\"\n",
    "dt_col = \"date\"\n",
    "obs_matrix = np.concatenate([y.reshape(-1, 1), x], axis=1)\n",
    "# make a data frame for orbit inputs\n",
    "df = pd.DataFrame(obs_matrix, columns=[response_col] + x_cols)\n",
    "# make some dummy date stamp\n",
    "dt = pd.date_range(start='2016-01-04', periods=SERIES_LEN, freq=\"1W\")\n",
    "df['date'] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:01:15.730128Z",
     "start_time": "2022-03-25T01:01:15.720117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 12)\n",
      "          y        x1        x2        x3        x4        x5        x6  \\\n",
      "0  4.426242  0.172792  0.000000  0.165219 -0.000000 -0.479769  0.240312   \n",
      "1  5.580432  0.452678  0.223187 -0.000000  0.290559 -0.970166 -1.296340   \n",
      "2  5.031773  0.182286  0.147066  0.014211  0.273356 -0.403479 -0.382158   \n",
      "3  3.264027 -0.368227 -0.081455 -0.241060  0.299423 -0.093035  0.447098   \n",
      "4  5.246511  0.019861 -0.146228 -0.390954 -0.128596  0.902981 -0.622541   \n",
      "\n",
      "         x7        x8        x9       x10       date  \n",
      "0  0.781391 -0.104744 -0.790966  0.245078 2016-01-10  \n",
      "1  0.841649  0.024343  0.694507 -0.141609 2016-01-17  \n",
      "2 -0.090071  2.223643 -0.060319 -1.234368 2016-01-24  \n",
      "3 -0.736534  1.631389 -0.426342  0.446477 2016-01-31  \n",
      "4 -3.756670  0.095822 -0.084870 -0.057588 2016-02-07  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WBIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we use DLT model as an example. Different DLT models (the number of features used changes) are fitted and their WBIC values are calculated respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:05:53.061817Z",
     "start_time": "2022-03-25T01:01:15.732651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:47:51 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n",
      "2024-01-21 13:48:03 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 1 regressors: 1202.020\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:48:16 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 2 regressors: 1149.747\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:48:28 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 3 regressors: 1103.782\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:48:40 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 4 regressors: 1054.616\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:48:52 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 5 regressors: 1060.191\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:05 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 6 regressors: 1066.616\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:18 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 7 regressors: 1072.969\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:30 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 8 regressors: 1079.379\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:42 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 1000 and samples(per chain): 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIC value with 9 regressors: 1084.309\n",
      "------------------------------------------------------------------\n",
      "WBIC value with 10 regressors: 1090.869\n",
      "------------------------------------------------------------------\n",
      "CPU times: user 22.3 s, sys: 1.01 s, total: 23.3 s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WBIC_ls = []\n",
    "for k in range(1, NUM_OF_REGRESSORS + 1):\n",
    "    regressor_col = x_cols[:k]\n",
    "    dlt_mod = DLT(\n",
    "        response_col=response_col,\n",
    "        date_col=dt_col,\n",
    "        regressor_col=regressor_col,\n",
    "        seed=2022,\n",
    "        # fixing the smoothing parameters to learn regression coefficients more effectively\n",
    "        level_sm_input=0.01,\n",
    "        slope_sm_input=0.01,\n",
    "        num_warmup=4000,\n",
    "        num_sample=4000,\n",
    "        stan_mcmc_args={'show_progress': False},\n",
    "    )\n",
    "    WBIC_temp = dlt_mod.fit_wbic(df=df) \n",
    "    print(\"WBIC value with {:d} regressors: {:.3f}\".format(k, WBIC_temp))\n",
    "    print('------------------------------------------------------------------')\n",
    "    WBIC_ls.append(WBIC_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also interesting to see if WBIC can distinguish between model types; not just do feature selection for a given type of model. To that end the next block fits an LGT and ETS model to the data; the WBIC values for both models are then calculated.  \n",
    "\n",
    "Note that WBIC is supported for both  the 'stan-mcmc' and 'pyro-svi' estimators. Currently only the LGT model has both. Thus WBIC is calculated for LGT for both estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:06:50.978628Z",
     "start_time": "2022-03-25T01:05:53.065054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:54 - orbit - INFO - Sampling (CmdStanPy) with chains: 4, cores: 8, temperature: 5.900, warmups (per chain): 225 and samples(per chain): 25.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a954b6fb9e8848ea9cc192a72dae3231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662a81384a442408ec6e72b0e03e54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22672e568fc74db0aeecce08e2224ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874c4dee313a4d65883a3e099bcbfe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 13:49:56 - orbit - INFO - Using SVI (Pyro) with steps: 301, samples: 100, learning rate: 0.1, learning_rate_total_decay: 1.0 and particles: 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WBIC value for LGT model (stan MCMC): 1143.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/towinazure/opt/miniconda3/envs/orbit39/lib/python3.9/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "2024-01-21 13:49:56 - orbit - INFO - step    0 loss = 299.39, scale = 0.11485\n",
      "INFO:orbit:step    0 loss = 299.39, scale = 0.11485\n",
      "2024-01-21 13:50:05 - orbit - INFO - step  100 loss = 116.84, scale = 0.5094\n",
      "INFO:orbit:step  100 loss = 116.84, scale = 0.5094\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgt = LGT(response_col=response_col,\n",
    "          date_col=dt_col,\n",
    "          regressor_col=regressor_col,\n",
    "          seasonality=52,\n",
    "          estimator='stan-mcmc',\n",
    "          seed=8888)\n",
    "WBIC_lgt_mcmc = lgt.fit_wbic(df=df) \n",
    "print(\"WBIC value for LGT model (stan MCMC): {:.3f}\".format(WBIC_lgt_mcmc))\n",
    "\n",
    "lgt = LGT(response_col=response_col,\n",
    "          date_col=dt_col,\n",
    "          regressor_col=regressor_col,\n",
    "          seasonality=52,\n",
    "          estimator='pyro-svi',\n",
    "          seed=8888)\n",
    "WBIC_lgt_pyro = lgt.fit_wbic(df=df) \n",
    "print(\"WBIC value for LGT model (pyro SVI): {:.3f}\".format(WBIC_lgt_pyro))\n",
    "\n",
    "ets = ETS(\n",
    "        response_col=response_col,\n",
    "        date_col=dt_col,\n",
    "        seed=2020,\n",
    "        # fixing the smoothing parameters to learn regression coefficients more effectively\n",
    "        level_sm_input=0.01,\n",
    "    )\n",
    "\n",
    "WBIC_ets = ets.fit_wbic(df=df) \n",
    "print(\"WBIC value for ETS model: {:.3f}\".format(WBIC_ets))\n",
    "\n",
    "WBIC_ls.append(WBIC_lgt_mcmc)\n",
    "WBIC_ls.append(WBIC_lgt_pyro)\n",
    "WBIC_ls.append(WBIC_ets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the WBIC vs the number of features / model type (blue line). The true model is indicated by the vertical red line. The horizontal gray line shows the minimum (optimal) value. The minimum is at the true value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:06:51.187435Z",
     "start_time": "2022-03-25T01:06:50.982429Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"DLT_{}\".format(x) for x in range(1, NUM_OF_REGRESSORS + 1)] + ['LGT_MCMC', 'LGT_SVI','ETS']\n",
    "fig, ax = plt.subplots(1, 1,figsize=(12, 6), dpi=80)\n",
    "markerline, stemlines, baseline = ax.stem(\n",
    "    np.arange(len(labels)), np.array(WBIC_ls), label='WBIC', markerfmt='D')\n",
    "baseline.set_color('none')\n",
    "markerline.set_markersize(12)\n",
    "ax.set_ylim(1020, )\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "# because list type is mixed index from 1;\n",
    "ax.axvline(x=NUM_OF_EFFECTIVE_REGRESSORS - 1, color='red', linewidth=3, alpha=0.5, linestyle='-', label='truth') \n",
    "ax.set_ylabel(\"WBIC\")\n",
    "ax.set_xlabel(\"# of Features / Model Type\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we use DLT model as an example. Different DLT models (the number of features used changes) are fitted and their BIC values are calculated respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:06:52.190878Z",
     "start_time": "2022-03-25T01:06:51.192123Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "BIC_ls = []\n",
    "for k in range(0, NUM_OF_REGRESSORS):\n",
    "    regressor_col = x_cols[:k + 1]\n",
    "    dlt_mod = DLT(\n",
    "        estimator='stan-map',\n",
    "        response_col=response_col,\n",
    "        date_col=dt_col,\n",
    "        regressor_col=regressor_col,\n",
    "        seed=2022,\n",
    "        # fixing the smoothing parameters to learn regression coefficients more effectively\n",
    "        level_sm_input=0.01,\n",
    "        slope_sm_input=0.01,\n",
    "        )\n",
    "    dlt_mod.fit(df=df)\n",
    "    BIC_temp = dlt_mod.get_bic() \n",
    "    print(\"BIC value with {:d} regressors: {:.3f}\".format(k + 1, BIC_temp))\n",
    "    print('------------------------------------------------------------------')\n",
    "    BIC_ls.append(BIC_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the BIC vs the number of features (blue line). The true model is indicated by the vertical red line. The horizontal gray line shows the minimum (optimal) value. The minimum is at the true value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T01:06:52.363849Z",
     "start_time": "2022-03-25T01:06:52.193136Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"DLT_{}\".format(x) for x in range(1, NUM_OF_REGRESSORS + 1)]\n",
    "fig, ax = plt.subplots(1, 1,figsize=(12, 6), dpi=80)\n",
    "markerline, stemlines, baseline = ax.stem(\n",
    "    np.arange(len(labels)), np.array(BIC_ls), label='BIC', markerfmt='D')\n",
    "baseline.set_color('none')\n",
    "markerline.set_markersize(12)\n",
    "ax.set_ylim(1020, )\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "# because list type is mixed index from 1;\n",
    "ax.axvline(x=NUM_OF_EFFECTIVE_REGRESSORS - 1, color='red', linewidth=3, alpha=0.5, linestyle='-', label='truth') \n",
    "ax.set_ylabel(\"BIC\")\n",
    "ax.set_xlabel(\"# of Features\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Watanabe Sumio (2010). \"Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory\". Journal of Machine Learning Research. 11: 3571–3594.\n",
    "2. McElreath Richard (2015). \"Statistical Rethinking: A Bayesian course with examples in R and Stan\" Secound Ed. 193-221.\n",
    "3. Vehtari Aki, Gelman Andrew, Gabry Jonah (2016) \"Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbit39",
   "language": "python",
   "name": "orbit39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
